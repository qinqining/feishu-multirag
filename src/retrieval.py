import os
import json
from typing import Tuple, List
from dotenv import load_dotenv
from loguru import logger

from langchain_community.vectorstores import Chroma
from langchain_dashscope import DashScopeEmbeddings
import dashscope
from dashscope import MultiModalConversation


load_dotenv()
api_key = os.getenv("DASHSCOPE_API_KEY")
dashscope.api_key = api_key


BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DB_PATH = os.path.join(BASE_DIR, "vector_db", "chroma_db")


embeddings = DashScopeEmbeddings(model="text-embedding-v3")
try:
    vector_store = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
    logger.info("âœ… æˆåŠŸè¿æ¥ ChromaDB å‘é‡åº“ï¼")
except Exception as e:
    logger.error(f"âŒ è¿æ¥ ChromaDB å¤±è´¥: {e}")
    vector_store = None


def get_answer(query: str) -> Tuple[str, List[str]]:
    """ä½¿ç”¨é˜¿é‡ŒåŸç”Ÿ MultiModalConversation æ¥å£ç”Ÿæˆå›ç­”"""
    if not vector_store:
        return "æŠ±æ­‰ï¼Œå‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–ã€‚", []

    logger.info(f"ğŸ” æ­£åœ¨æ£€ç´¢é—®é¢˜: {query}")
    
    chunks = vector_store.similarity_search(query, k=2)
    
    if not chunks:
        return "æŠ±æ­‰ï¼ŒçŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚", []

    try:
        prompt_text = f"è¯·ä½¿ç”¨ä¸Šè¿°æ–‡æœ¬ã€è¡¨æ ¼å’Œå›¾ç‰‡ï¼Œæä¾›æ¸…æ™°ã€å…¨é¢çš„ç­”æ¡ˆã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”è¯¥é—®é¢˜ï¼Œè¯·è¯´æ˜ï¼šâ€œæ ¹æ®æä¾›çš„æ–‡æ¡£ï¼Œæˆ‘æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªé—®é¢˜{query}\n\nå†…å®¹ï¼š\n"
        message_content = []
        all_images_base64 = [] # ç”¨äºäº¤ç»™ main.py ä¸Šä¼ é£ä¹¦
        
        for i, chunk in enumerate(chunks):
            prompt_text += f"--- åˆ†å— {i+1} ---\n"
            
            if "original_content" in chunk.metadata:
                try:
                    meta = json.loads(chunk.metadata["original_content"])
                    prompt_text += f"æ–‡å­—å†…å®¹ï¼š\n{meta.get('raw_text', '')}\n"
                    
                    # å¤„ç†å›¾ç‰‡ï¼šç»„è£…æˆåŸç”Ÿ SDK è¦æ±‚çš„æ ¼å¼
                    for img_b64 in meta.get("images_base64", []):
                        # æ¸…æ´—ç¡®ä¿æœ‰æ­£ç¡®å‰ç¼€
                        clean_b64 = img_b64.split(",")[-1] if "," in img_b64 else img_b64
                        fixed_img = f"data:image/jpeg;base64,{clean_b64}"
                        
                        # åŠ å…¥æ¨¡å‹ä¸Šä¸‹æ–‡
                        message_content.append({"image": fixed_img})
                        # å­˜å…¥åˆ—è¡¨äº¤å›ç»™é£ä¹¦
                        all_images_base64.append(clean_b64)
                except json.JSONDecodeError:
                    prompt_text += f"{chunk.page_content}\n"
            else:
                prompt_text += f"{chunk.page_content}\n"

        # å°† Prompt æ–‡æœ¬æ’å…¥åˆ°æ¶ˆæ¯æ•°ç»„çš„é¦–ä½ (å’Œä½ çš„å‰ç«¯é€»è¾‘ä¸€æ¨¡ä¸€æ ·)
        message_content.insert(0, {"text": prompt_text})

        logger.info("ğŸ§  æ­£åœ¨é€šè¿‡é˜¿é‡ŒåŸç”Ÿå¤šæ¨¡æ€ SDK å‘¼å« Qwen3-VL-Plus...")
        
        # ğŸš¨ æ ¸å¿ƒæ”¹åŠ¨ï¼šä½¿ç”¨èƒ½ 100% è·‘é€šçš„åŸç”Ÿè°ƒç”¨æ–¹å¼
        response = MultiModalConversation.call(
            model='qwen3-vl-plus',  # æˆ–è€…å¡«ä½ å‰ç«¯ç”¨çš„å…·ä½“ç‰ˆæœ¬å·
            messages=[{"role": "user", "content": message_content}]
        )

        # è§£æåŸç”Ÿ SDK çš„è¿”å›ç»“æœ
        if response.status_code == 200:
            # æ‹¿åˆ°æœ€ç»ˆçš„æ–‡å­—å›ç­”
            answer = response.output.choices[0].message.content[0]['text']
            logger.info("âœ… åŸç”Ÿæ¥å£è°ƒç”¨æˆåŠŸï¼Œå›ç­”å·²ç”Ÿæˆï¼")
            return answer, all_images_base64
        else:
            logger.error(f"âŒ é˜¿é‡Œäº‘æ¥å£æŠ¥é”™: {response.code} - {response.message}")
            return f"æŠ±æ­‰ï¼Œå¤§æ¨¡å‹åˆ†æå¤±è´¥ï¼š{response.message}", []
            
    except Exception as e:
        logger.error(f"âŒ å›ç­”ç”Ÿæˆè¿‡ç¨‹å‘ç”Ÿä»£ç å¼‚å¸¸: {e}")
        return "æŠ±æ­‰ï¼Œç³»ç»Ÿå¤„ç†æ—¶å‘ç”Ÿå†…éƒ¨æ•…éšœã€‚", []
import json
from langchain_core.documents import Document
import dashscope
from dotenv import load_dotenv
load_dotenv()

def separate_content_types(chunk):
    """Analyze what types of content are in a chunk"""
    content_data = {
        'text': chunk.text,
        'tables': [],
        'images': [],
        'types': ['text']
    }
    
    # Check for tables and images in original elements
    if hasattr(chunk, 'metadata') and hasattr(chunk.metadata, 'orig_elements'):
        for element in chunk.metadata.orig_elements:
            element_type = type(element).__name__
            
            # Handle tables
            if element_type == 'Table':
                content_data['types'].append('table')
                table_html = getattr(element.metadata, 'text_as_html', element.text)
                content_data['tables'].append(table_html)
            
            # Handle images
            elif element_type == 'Image':
                if hasattr(element, 'metadata') and hasattr(element.metadata, 'image_base64'):
                    content_data['types'].append('image')
                    content_data['images'].append(element.metadata.image_base64)
    
    content_data['types'] = list(set(content_data['types']))
    return content_data

def create_ai_enhanced_summary(text: str, tables: list[str], images: list[str]) -> str:
    """ä½¿ç”¨ Qwen3-VL åˆ›å»ºå¤šæ¨¡æ€å¢å¼ºæ‘˜è¦"""
    
    try:
        
        # 1. æ„å»ºæç¤ºè¯æ–‡æœ¬
        instruction = """ä½ çš„ä»»åŠ¡ï¼š
ç”Ÿæˆä¸€ä»½å…¨é¢ã€ä¾¿äºæ£€ç´¢çš„æè¿°ï¼Œéœ€æ¶µç›–ä»¥ä¸‹å†…å®¹ï¼š
æ¥è‡ªæ–‡æœ¬å’Œè¡¨æ ¼çš„å…³é”®äº‹å®ã€æ•°å­—ä¸æ•°æ®è¦ç‚¹
æ‰€è®¨è®ºçš„ä¸»è¦ä¸»é¢˜ä¸æ ¸å¿ƒæ¦‚å¿µ
æ­¤å†…å®¹èƒ½å¤Ÿå›ç­”çš„é—®é¢˜
è§†è§‰å†…å®¹åˆ†æï¼ˆå›¾è¡¨ã€ç¤ºæ„å›¾ã€å›¾ç‰‡ä¸­çš„è§„å¾‹ç­‰ï¼‰
ç”¨æˆ·å¯èƒ½ä½¿ç”¨çš„æ›¿ä»£æœç´¢è¯
è¯·ç¡®ä¿æè¿°è¯¦ç»†ä¸”ä¾¿äºæ£€ç´¢ â€”â€” ä¼˜å…ˆè€ƒè™‘å¯æŸ¥æ‰¾æ€§ï¼Œè€Œéç®€æ´æ€§ã€‚
å¯æ£€ç´¢æè¿°ï¼š"""
        
        content_parts = [{"text": instruction}]
        
        # 2. åŠ å…¥æ–‡æœ¬å’Œè¡¨æ ¼ç´ æ
        prompt_body = f"\nã€å¾…åˆ†ææ–‡æœ¬å†…å®¹ã€‘:\n{text}\n"
        if tables:
            prompt_body += "\nã€è¡¨æ ¼æ•°æ®ã€‘:\n"
            for i, table in enumerate(tables):
                prompt_body += f"è¡¨æ ¼ {i+1}:\n{table}\n"
        
        content_parts.append({"text": prompt_body})
        
        # 3. åŠ å…¥å›¾ç‰‡ç´ æ 
        # images åº”è¯¥æ˜¯ base64 å­—ç¬¦ä¸²æˆ–æœ¬åœ°è·¯å¾„
        if images:
            for img in images:
                # å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼ŒQwen2-VL æ¥å— file:// åè®®ï¼›å¦‚æœæ˜¯ base64ï¼Œåˆ™æŒ‰æ ‡å‡†æ ¼å¼å¤„ç†
                # æ£€æŸ¥ img æ˜¯å¦æ˜¯åŸå§‹ Base64ï¼ˆå³ä¸åŒ…å« data: å‰ç¼€ä¸”ä¸æ˜¯ URLï¼‰
                if isinstance(img, str) and not img.startswith(('http', 'file://', 'data:')):
                    # æ‹¼æ¥æ ‡å‡†çš„ Data URI å‰ç¼€
                    img_formatted = f"data:image/png;base64,{img}"
                else:
                    img_formatted = img
                
                content_parts.append({"image": img_formatted})

        # 4. è°ƒç”¨ DashScope (å‡è®¾ä½ å·²é…ç½®å¥½ç¯å¢ƒå˜é‡)
        # è¿™é‡Œå±•ç¤ºæ ‡å‡† SDK è°ƒç”¨ï¼Œå¦‚æœä½ ç”¨çš„æ˜¯ LangChain çš„ ChatDashScope é€»è¾‘ä¹Ÿç±»ä¼¼
        response = dashscope.MultiModalConversation.call(
            model='qwen3-vl-plus-2025-12-19', 
            messages=[{
                'role': 'user',
                'content': content_parts
            }]
        )

        if response.status_code == 200:
            return response.output.choices[0].message.content[0]['text']
        else:
            return f"Error: {response.code} - {response.message}"

    except Exception as e:
        return f"AI æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"

def summarise_chunks(chunks):
    """Process all chunks with AI Summaries"""
    print("ğŸ§  Processing chunks with AI Summaries...")
    
    langchain_documents = []
    total_chunks = len(chunks)
    
    for i, chunk in enumerate(chunks):
        current_chunk = i + 1
        print(f"   Processing chunk {current_chunk}/{total_chunks}")
        
        # Analyze chunk content
        content_data = separate_content_types(chunk)
        
        # Debug prints
        print(f"     Types found: {content_data['types']}")
        print(f"     Tables: {len(content_data['tables'])}, Images: {len(content_data['images'])}")
        
        # Create AI-enhanced summary if chunk has tables/images
        if content_data['tables'] or content_data['images']:
            print(f"     â†’ Creating AI summary for mixed content...")
            try:
                enhanced_content = create_ai_enhanced_summary(
                    content_data['text'],
                    content_data['tables'], 
                    content_data['images']
                )
                print(f"     â†’ AI summary created successfully")
                print(f"     â†’ Enhanced content preview: {enhanced_content[:200]}...")
            except Exception as e:
                print(f"     âŒ AI summary failed: {e}")
                enhanced_content = content_data['text']
        else:
            print(f"     â†’ Using raw text (no tables/images)")
            enhanced_content = content_data['text']
        
        # Create LangChain Document with rich metadata
        doc = Document(
            page_content=enhanced_content,
            metadata={
                "original_content": json.dumps({
                    "raw_text": content_data['text'],
                    "tables_html": content_data['tables'],
                    "images_base64": content_data['images']
                })
            }
        )
        
        langchain_documents.append(doc)
    
    print(f"âœ… Processed {len(langchain_documents)} chunks")
    return langchain_documents


def export_chunks_to_json(chunks, filename="chunks_export.json"):
    """Export processed chunks to clean JSON format"""
    export_data = []
    
    for i, doc in enumerate(chunks):
        chunk_data = {
            "chunk_id": i + 1,
            "enhanced_content": doc.page_content,
            "metadata": {
                "original_content": json.loads(doc.metadata.get("original_content", "{}"))
            }
        }
        export_data.append(chunk_data)
    
    # Save to file
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Exported {len(export_data)} chunks to {filename}")
    return export_data